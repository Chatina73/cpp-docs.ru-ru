---
title: Г. Использование предложения schedule
ms.date: 11/04/2016
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: 85386c913a6e447ba9e71231be8b951eef504fea
ms.sourcegitcommit: 6052185696adca270bc9bdbec45a626dd89cdcdd
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/31/2018
ms.locfileid: "50627530"
---
# <a name="d-using-the-schedule-clause"></a>Г. Использование предложения schedule

Область параллельной обработки имеет по крайней мере одного барьера, со своей стороны и может иметь дополнительные препятствия в ней. На каждом барьере другими членами команды необходимо дождаться прибытия последнего потока. Чтобы свести к минимуму время ожидания, общих рабочих распределить, таким образом, чтобы все потоки достигнут барьера, в то же время. Если некоторыми из этих общих рабочих содержится в **для** конструкции `schedule` предложение может использоваться для этой цели.

При наличии повторные ссылки на те же объекты, Выбор расписания для **для** конструкции можно было определить, главным образом характеристики памяти системы, такие как наличие и размер кэша и ли обращаться к памяти значения времени указаны универсальный или с неоднородным доступом. Такие рекомендации может сделать ее более предпочтительной каждый поток постоянно ссылаться на тот же набор элементов в массиве, в ряде циклов, даже если некоторые потоки назначаются относительно меньше работы в некоторых из циклов. Это можно сделать с помощью **статический** расписание с теми же границами для все циклы. В следующем примере обратите внимание, что ноль, даже если используется в качестве нижней границы в втором цикле **k** окажется естественнее, если расписание не использовались.

```
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

В остальных примерах предполагается, что память доступа не является главным рассмотрения и, если не указано иное, что все потоки имеют сравнимые вычислительные ресурсы. В таких случаях выбор расписания для **для** конструкция зависит от общих рабочих, который должен выполняться между ближайшего предшествующего барьера и барьера подразумеваемых закрытия или ближайшее последующих барьера, если имеется `nowait` предложение. Для каждого вида расписание краткий пример показано, как этот вид расписания скорее всего, лучший выбор. Краткое описание каждого примера приводится.

**Статический** расписание также подходит для простейшем случае область параллельной обработки, содержит один **для** построения, с каждой итерации требуется одинаковый объем работы.

```
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

**Статический** расписание характеризуется свойства, каждый поток получает приблизительно одинаковое количество итераций как любого другого потока, а каждый поток независимо друг от друга определить итерации, назначенные его. Таким образом синхронизация не требуется для распределения работы и, исходя из предположения, что для каждой итерации требуется одинаковый объем работы, все потоки должны оканчиваться на приблизительно за одинаковое время.

Группа `p` потоков, позвольте *ceiling(n/p)* быть целым числом *q*, который удовлетворяет *n = p\*q - r* с *0 < = r < p* . Одна реализация **статический** запланировать на этом примере будет назначать *q* итераций первому *p-1* потоков, и *q-r* итераций для последнего потока.  Будет назначен другой допустимый реализации *q* итераций первому *p — r* потоков, и *q-1* итераций для оставшихся *r*потоков. Это объясняется, почему программа не следует полагаться на сведения о конкретной реализации.

**Динамическое** расписание подходит в случае **для** построения с итерациями, требующие различных или даже невозможно спрогнозировать, объемы работы.

```
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

**Динамическое** расписание характеризуется свойство, которое ни один поток ожидает на барьера больше времени, чем он принимает другой поток для выполнения его последней итерации. Для этого на итерации должны быть назначены поочередно потоков, которые становятся доступными при синхронизации для каждого назначения. Можно сократить затраты на синхронизацию, указав минимальный размер блока *k* больше, чем 1, чтобы потоки назначаются *k* за один раз до менее *k* остаются. Это гарантирует, что ни один поток не будет ждать в барьера, превышает время другой поток для выполнения его окончательный блок (максимум) *k* итераций.

**Динамическое** расписания могут быть полезны при потоки имеют различные вычислительные ресурсы, в которой действует во многом так же, как различные объемы работы для каждой итерации. Аналогичным образом, динамические расписание также можно использовать, если потоки образовать **для** конструкции в различные моменты времени, хотя в некоторых из этих случаев **интерактивной** расписание может быть предпочтительнее.

**Интерактивной** расписание подходит для случая, в котором потоки могут поступать в различные моменты времени в **для** построения с каждой итерации, требуется примерно столько же работы. Это может произойти, если, например **для** конструкция предшествует один или несколько разделов или **для** конструкции `nowait` предложения.

```
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

Как и **динамическое**, **интерактивной** запланировать гарантирует, что ни один поток ожидает на барьера превышает время другой поток для выполнения его последней итерации или окончательной *k* итерации, если размер блока *k* указан. Среди таких расписания **интерактивной** расписание характеризуется свойство требует минимальное число синхронизаций. Для размера блока *k*, типичная реализация назначит *q = ceiling(n/p)* итераций первый доступный поток, задайте *n* в соответствии с большим из *n-q* и *p\*k*и повторение всех итераций пока будет назначен.

Если выбрать оптимальное расписание не настолько очивдны, как и для этих примерах **среды выполнения** расписание удобно использовать для экспериментов с различные расписания и размера блоков без необходимости измените и перекомпилируйте программу. Его также можно использовать при оптимальное расписание зависит (в некоторых предсказуемым способом) входные данные, к которому применяется программа.

Чтобы увидеть пример компромиссы между различные расписания, мы рекомендуем публиковать 1000 итераций по 8 потокам. Предположим, что Инвариантное объем работы в каждой итерации и использовать его в качестве единицы времени.

Если запустить все потоки, в то же время **статический** расписание приведет к конструкции для выполнения в 125 единиц, без синхронизации. Однако предположим, что один поток является 100 единиц в конце поступающих. Дождитесь 100 единиц в барьера оставшиеся семь потоки и время выполнения конструкция в целом возрастает до 225.

Поскольку как **динамическое** и **интерактивной** расписания убедитесь, что ни один поток ожидает в течение более чем одной единицы в барьера, отложенной поток вызывает для них времени выполнения для конструкции только увеличится до 138 единицы, возможно повышение задержки в синхронизации. Если такие задержки не незначительно, становится важным, что число синхронизаций равно 1000 для **динамическое** , но только 41 для **интерактивной**, при условии, что размер блока по умолчанию одного. С 25, размер блока **динамическое** и **интерактивной** Готово в 150 единиц, а также все возможные задержки из требуется синхронизация, номер, который теперь только 40 до 20, соответственно.