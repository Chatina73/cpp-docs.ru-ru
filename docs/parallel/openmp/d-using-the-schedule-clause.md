---
description: 'Дополнительные сведения: D. Предложение Schedule'
title: Г. Предложение schedule
ms.date: 01/22/2019
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: bd1bb4f9a6c661205e2e647fc9e45d81903008c8
ms.sourcegitcommit: d6af41e42699628c3e2e6063ec7b03931a49a098
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/11/2020
ms.locfileid: "97342495"
---
# <a name="d-the-schedule-clause"></a>Г. Предложение schedule

Параллельная область имеет по крайней мере одно барьер в своем конце и может иметь дополнительные барьеры. В каждом барьере другие члены команды должны ожидать поступления последнего потока. Чтобы максимально сокращать время ожидания, необходимо распределить общую работу, чтобы все потоки поступали в барьер примерно в то же время. Если часть этой общей работы содержится в `for` конструкциях, `schedule` для этой цели можно использовать предложение.

При наличии повторяющихся ссылок на одни и те же объекты можно определить расписание для конструкции в `for` первую очередь характеристиками системы памяти, такими как присутствие и размер кэшей, а также то, являются ли времена доступа к памяти универсальными или неоднородным доступом. Например, можно сделать так, чтобы каждый поток постоянно ссылался на один и тот же набор элементов массива в серии циклов, даже если некоторым потокам в некоторых циклах назначено относительно меньше работы. Эту настройку можно выполнить с помощью `static` расписания с одинаковыми границами для всех циклов. В следующем примере ноль используется в качестве нижней границы во втором цикле, даже `k` Если расписание не имеет значения, но было бы более естественным.

```cpp
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

В остальных примерах предполагается, что доступ к памяти не является главным фактором. Если не указано иное, все потоки получают сравнимые вычислительные ресурсы. В таких случаях выбор расписания для `for` конструкции зависит от всей общей работы, которая должна выполняться между ближайшим предыдущим барьером, а также с подразумеваемым барьером или ближайшим барьером, если есть `nowait` предложение. Для каждого типа расписания короткий пример показывает, что этот тип расписания, скорее всего, будет лучшим выбором. Ниже приведено краткое обсуждение.

`static`Расписание также подходит для простейшего случая, параллельной области, содержащей одну `for` конструкцию, с каждой итерацией, для которой требуется одинаковый объем работы.

```cpp
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

`static`Расписание характеризуется свойствами, которые каждый поток получает приблизительно такое же количество итераций, как и любой другой поток, и каждый поток может независимо определить итерации, назначенные ему. Поэтому для распределения работы не требуется синхронизация, и в соответствии с предположением, что каждая итерация требует одинакового объема работы, все потоки должны завершаться примерно в одно и то же время.

Для команды *p* threads можно использовать целое число *q* *(n/p)* , которое соответствует *n = p \* q-r* и *0 <= r < p*. Одной из реализаций `static` расписания для этого примера будет назначение итераций *q* первым потокам *p-1* , а в последнем потоке — число итераций *q-r* .  Другая допустимая реализация назначит итерации *q* первым потокам *p-r* , а остальные *— 1* итерации — оставшимся потокам *r* . В этом примере показано, почему программа не должна полагаться на сведения о конкретной реализации.

`dynamic`Расписание подходит для случая `for` конструкции с итерациями, в которых требуются разные или даже непредсказуемые объемы работы.

```cpp
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

`dynamic`Расписание характеризуется свойством, которое ни один поток не ждет в барьере дольше, чем он принимает другой поток для выполнения своей конечной итерации. Это требование означает, что итерации должны быть назначены по одному потоку, как только они становятся доступными, с синхронизацией для каждого назначения. Затраты на синхронизацию можно уменьшить, указав минимальный размер блока *k* больше 1, чтобы потоки были назначены *k* в течение определенного времени до тех пор, пока не будет осталось меньше *k* . Это гарантирует, что ни один поток не ждет в барьере дольше, чем он принимает другой поток для выполнения последнего фрагмента (не *более)* итераций.

`dynamic`Расписание может быть полезным, если потоки получают различные вычислительные ресурсы, что оказывает существенное воздействие на разные объемы работы для каждой итерации. Аналогичным образом динамическое расписание также может быть полезно, если потоки прибывают к `for` конструкции в разное время, хотя в некоторых из этих случаев `guided` Расписание может быть предпочтительным.

`guided`Расписание подходит для случая, когда потоки могут поступать в разные моменты времени в `for` конструкции с каждой итерацией, требующей примерно одинакового объема работы. Такая ситуация может возникнуть, например, если `for` конструкции предшествует один или несколько разделов или `for` конструкций с `nowait` предложениями.

```cpp
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

Как и `dynamic` в случае, `guided` Расписание гарантирует, что ни один поток не ждет в барьере дольше, чем он принимает другой поток для выполнения его  окончательной итерации или завершающие итерации, если указан размер фрагмента *k* . В таких расписаниях `guided` Расписание характеризуется свойством, которое требует наименьшей синхронизации. Для размера фрагмента *k* Типичная реализация применяет итерации *q = ceiling (n/p)* к первому доступному потоку, устанавливает *n* в большее значение *n-q* и *p \* k* и повторяется до тех пор, пока не будут назначены все итерации.

Если выбор оптимального расписания не так ясны, как в этих примерах, `runtime` Расписание удобно для экспериментов с различными расписаниями и размерами фрагментов без необходимости изменения и повторной компиляции программы. Он также может быть полезен, если оптимальное расписание зависит от входных данных, к которым применяется программа, в определенном предсказуемом виде.

Чтобы увидеть пример компромиссов между различными расписаниями, рассмотрите возможность совместного использования итераций 1000 в восьми потоках. Предположим, что в каждой итерации есть инвариантный объем работы, который используется в качестве единицы времени.

Если все потоки начинаются в одно и то же время, это `static` Расписание приведет к выполнению конструкции в 125 единиц, без синхронизации. Но предположим, что один поток — 100 единиц в поступающих. Затем оставшиеся семь потоков ожидают 100 единиц в барьере, а время выполнения для всей конструкции увеличивается до 225.

Так как `dynamic` расписания и `guided` не позволяют ожидать, что ни один поток не ждет более одной единицы в барьере, задержанный поток приводит к тому, что время их выполнения для конструкции увеличивается только до 138 единиц, что может увеличиться за счет задержек синхронизации. Если такие задержки не происходят незначительно, то важно, чтобы количество синхронизаций 1000 для `dynamic` , но только 41 для `guided` , предполагая, что размер блока по умолчанию равен единице. С размером фрагмента 25 `dynamic` и `guided` обоими в 150 единицах плюс любые задержки от требуемых синхронизаций, которые теперь нумеруются только 40 и 20 соответственно.
