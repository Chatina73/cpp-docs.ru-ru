---
title: Г. Предложения schedule
ms.date: 01/22/2019
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: 89e011784c5cccedc4a75f38d553458ea2e5d7e0
ms.sourcegitcommit: 382e247c0f1b4cb7c2dab837b8b6fdff24bff47a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2019
ms.locfileid: "55087292"
---
# <a name="d-the-schedule-clause"></a>Г. Предложения schedule

Область параллельной обработки имеет по крайней мере одного барьера, со своей стороны и может иметь дополнительные препятствия в ней. На каждом барьере другими членами команды необходимо дождаться прибытия последнего потока. Чтобы свести к минимуму время ожидания, общих рабочих распределить, таким образом, чтобы все потоки достигнут барьера, в то же время. Если некоторыми из этих общих рабочих содержится в `for` конструкции `schedule` предложение может использоваться для этой цели.

При наличии повторные ссылки на те же объекты, Выбор расписания для `for` конструкции можно было определить, главным образом характеристики памяти системы, такие как наличие и размер кэша и времени доступа к памяти, являются ли универсальный код или nonuniform. Такие рекомендации может сделать ее более предпочтительной каждый поток постоянно ссылаться на тот же набор элементов в массиве, в ряде циклов, даже если некоторые потоки назначаются относительно меньше работы в некоторых из циклов. Эта настройка может осуществляться с помощью `static` расписание с теми же границами для все циклы. В следующем примере используется ненулевое качестве нижней границы во втором цикле, даже если `k` окажется естественнее, если расписание не использовались.

```cpp
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

В остальных примерах, предполагается, что память доступа не главный рассмотрения. Если не указано иное, что все потоки имеют сравнимые вычислительные ресурсы. В таких случаях выбор расписания для `for` конструкция зависит от общих рабочих, который должен выполняться между ближайшего предшествующего барьера и барьера подразумеваемых закрытия или ближайшее предстоящих барьера, если имеется `nowait` предложение. Для каждого вида расписание краткий пример показано, как этот вид расписания скорее всего, лучший выбор. Краткое описание каждого примера приводится.

`static` Расписание также подходит для простейшем случае область параллельной обработки, содержит один `for` построения, с каждой итерации требуется одинаковый объем работы.

```cpp
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

`static` Расписание характеризуется свойства, каждый поток получает приблизительно одинаковое количество итераций как любого другого потока, а каждый поток независимо друг от друга определить итерации, назначенные его. Таким образом синхронизация не требуется для распределения работы и, исходя из предположения, что для каждой итерации требуется одинаковый объем работы, все потоки должны оканчиваться на приблизительно за одинаковое время.

Группа *p* потоков, позвольте *ceiling(n/p)* быть целым числом *q*, который удовлетворяет *n = p\*q - r* с *0 < = r < p*. Одна реализация `static` запланировать на этом примере будет назначать *q* итераций первому *p-1* потоков, и *q-r* итераций для последнего потока.  Будет назначен другой допустимый реализации *q* итераций первому *p — r* потоков, и *q-1* итераций для оставшихся *r*потоков. Этот пример иллюстрирует, почему программа не стоит полагаться на сведения о конкретной реализации.

`dynamic` Расписание подходит в случае `for` построения с итерациями, требующие различных или даже невозможно спрогнозировать, объемы работы.

```cpp
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

`dynamic` Расписание характеризуется свойство, которое ни один поток ожидает на барьера больше времени, чем он принимает другой поток для выполнения его последней итерации. Это требование означает, что итерации должны быть назначены поочередно потоков, как только они становятся доступными при синхронизации для каждого назначения. Можно сократить затраты на синхронизацию, указав минимальный размер блока *k* больше, чем 1, чтобы потоки назначаются *k* за один раз до менее *k* остаются. Это гарантирует, что ни один поток не будет ждать в барьера, превышает время другой поток для выполнения его окончательный блок (максимум) *k* итераций.

`dynamic` Расписания могут быть полезны при потоки имеют различные вычислительные ресурсы, в которой действует во многом так же, как различные объемы работы для каждой итерации. Аналогичным образом, динамические расписание также можно использовать, если потоки образовать `for` конструкции в различные моменты времени, хотя в некоторых из этих случаев `guided` расписание может быть предпочтительнее.

`guided` Расписание подходит для случая, в котором потоки могут поступать в различные моменты времени в `for` построения с каждой итерации, требуется примерно столько же работы. Это может происходить, если, например `for` конструкция предшествует один или несколько разделов или `for` конструкции `nowait` предложения.

```cpp
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

Как и `dynamic`, `guided` запланировать гарантирует, что ни один поток ожидает на барьера превышает время другой поток для выполнения его последней итерации или окончательной *k* итераций, если размер блока *k* указан. Среди таких расписания `guided` расписание характеризуется свойство требует минимальное число синхронизаций. Для размера блока *k*, типичная реализация назначит *q = ceiling(n/p)* итераций первый доступный поток, задайте *n* в соответствии с большим из *n-q* и *p\*k*и повторение всех итераций пока будет назначен.

Если выбрать оптимальное расписание не настолько очивдны, как и для этих примерах `runtime` расписание удобно использовать для экспериментов с различные расписания и размера блоков без необходимости измените и перекомпилируйте программу. Его также можно использовать при оптимальное расписание зависит (в некоторых предсказуемым способом) входные данные, к которому применяется программа.

Чтобы просмотреть пример компромиссы между различные расписания, мы рекомендуем публиковать 1000 итераций среди восемь потоков. Предположим, что Инвариантное объем работы в каждой итерации и использовать его в качестве единицы времени.

Если запустить все потоки, в то же время `static` расписание приведет к конструкции для выполнения в 125 единиц, без синхронизации. Однако предположим, что один поток является 100 единиц в конце поступающих. Дождитесь 100 единиц в барьера оставшиеся семь потоки и время выполнения конструкция в целом возрастает до 225.

Поскольку как `dynamic` и `guided` расписания убедитесь, что ни один поток ожидает в течение более чем одной единицы в барьера, отложенной поток вызывает для них времени выполнения для конструкции увеличить только до 138 единиц, возможно, увеличивается задержка из синхронизация. Если такие задержки не незначительно, становится важным, что число синхронизаций равно 1000 для `dynamic` , но только 41 для `guided`, при условии, что размер блока по умолчанию одного. С 25, размер блока `dynamic` и `guided` Готово в 150 единиц, а также все возможные задержки из требуется синхронизация, номер, который теперь только 40 до 20, соответственно.
